{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from pandas import DataFrame\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20715, 787)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyto.10p11.1</th>\n",
       "      <th>cyto.10p11.21</th>\n",
       "      <th>cyto.10p11.22</th>\n",
       "      <th>cyto.10p11.23</th>\n",
       "      <th>cyto.10p12.1</th>\n",
       "      <th>cyto.10p12.2</th>\n",
       "      <th>cyto.10p12.31</th>\n",
       "      <th>cyto.10p12.32</th>\n",
       "      <th>cyto.10p12.33</th>\n",
       "      <th>cyto.10p13</th>\n",
       "      <th>...</th>\n",
       "      <th>cyto.9q32</th>\n",
       "      <th>cyto.9q33.1</th>\n",
       "      <th>cyto.9q33.2</th>\n",
       "      <th>cyto.9q33.3</th>\n",
       "      <th>cyto.9q34.11</th>\n",
       "      <th>cyto.9q34.12</th>\n",
       "      <th>cyto.9q34.13</th>\n",
       "      <th>cyto.9q34.2</th>\n",
       "      <th>cyto.9q34.3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1608</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>BLCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2733</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>BLCA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cyto.10p11.1  cyto.10p11.21  cyto.10p11.22  cyto.10p11.23  cyto.10p12.1  \\\n",
       "0       -0.1608         0.2213         0.2213         0.2213        0.2213   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017       -0.0017   \n",
       "2       -0.2733         0.0403         0.0403         0.0403        0.0356   \n",
       "\n",
       "   cyto.10p12.2  cyto.10p12.31  cyto.10p12.32  cyto.10p12.33  cyto.10p13  ...  \\\n",
       "0        0.2213         0.2213         0.2213         0.2213      0.2213  ...   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017     -0.0017  ...   \n",
       "2        0.0356         0.0356         0.0356         0.0356      0.0356  ...   \n",
       "\n",
       "   cyto.9q32  cyto.9q33.1  cyto.9q33.2  cyto.9q33.3  cyto.9q34.11  \\\n",
       "0    -0.1732      -0.1732      -0.1732      -0.1732       -0.1732   \n",
       "1     0.0009       0.0009       0.0009       0.0009        0.0009   \n",
       "2    -0.2716      -0.2716      -0.2716      -0.2716       -0.3456   \n",
       "\n",
       "   cyto.9q34.12  cyto.9q34.13  cyto.9q34.2  cyto.9q34.3       y  \n",
       "0       -0.1732       -0.1732      -0.1732      -0.1732    BLCA  \n",
       "1        0.0009        0.0009       0.0009       0.0009  Normal  \n",
       "2       -0.3456        0.2685      -0.3587      -0.3587    BLCA  \n",
       "\n",
       "[3 rows x 787 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcga = pd.read_csv('TCGA_data.csv')\n",
    "tcga.drop('cancer',axis=1,inplace=True)\n",
    "tcga = tcga.sort_index(axis=1)\n",
    "print(tcga.shape)\n",
    "tcga.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyto.10p11.1</th>\n",
       "      <th>cyto.10p11.21</th>\n",
       "      <th>cyto.10p11.22</th>\n",
       "      <th>cyto.10p11.23</th>\n",
       "      <th>cyto.10p12.1</th>\n",
       "      <th>cyto.10p12.2</th>\n",
       "      <th>cyto.10p12.31</th>\n",
       "      <th>cyto.10p12.32</th>\n",
       "      <th>cyto.10p12.33</th>\n",
       "      <th>cyto.10p13</th>\n",
       "      <th>...</th>\n",
       "      <th>cyto.9q32</th>\n",
       "      <th>cyto.9q33.1</th>\n",
       "      <th>cyto.9q33.2</th>\n",
       "      <th>cyto.9q33.3</th>\n",
       "      <th>cyto.9q34.11</th>\n",
       "      <th>cyto.9q34.12</th>\n",
       "      <th>cyto.9q34.13</th>\n",
       "      <th>cyto.9q34.2</th>\n",
       "      <th>cyto.9q34.3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1608</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>BLCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2733</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>BLCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cyto.10p11.1  cyto.10p11.21  cyto.10p11.22  cyto.10p11.23  cyto.10p12.1  \\\n",
       "0       -0.1608         0.2213         0.2213         0.2213        0.2213   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017       -0.0017   \n",
       "2       -0.2733         0.0403         0.0403         0.0403        0.0356   \n",
       "3        0.0013         0.0013         0.0013         0.0013       -0.0057   \n",
       "4       -0.0003        -0.0003        -0.0003        -0.0003       -0.0003   \n",
       "\n",
       "   cyto.10p12.2  cyto.10p12.31  cyto.10p12.32  cyto.10p12.33  cyto.10p13  ...  \\\n",
       "0        0.2213         0.2213         0.2213         0.2213      0.2213  ...   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017     -0.0017  ...   \n",
       "2        0.0356         0.0356         0.0356         0.0356      0.0356  ...   \n",
       "3        0.0053         0.0053         0.0053         0.0053      0.0053  ...   \n",
       "4       -0.0002        -0.0002        -0.0002        -0.0002     -0.0002  ...   \n",
       "\n",
       "   cyto.9q32  cyto.9q33.1  cyto.9q33.2  cyto.9q33.3  cyto.9q34.11  \\\n",
       "0    -0.1732      -0.1732      -0.1732      -0.1732       -0.1732   \n",
       "1     0.0009       0.0009       0.0009       0.0009        0.0009   \n",
       "2    -0.2716      -0.2716      -0.2716      -0.2716       -0.3456   \n",
       "3     0.0015       0.0015       0.0015       0.0015        0.0015   \n",
       "4    -0.0024      -0.0024      -0.0024      -0.0024       -0.0024   \n",
       "\n",
       "   cyto.9q34.12  cyto.9q34.13  cyto.9q34.2  cyto.9q34.3       y  \n",
       "0       -0.1732       -0.1732      -0.1732      -0.1732    BLCA  \n",
       "1        0.0009        0.0009       0.0009       0.0009  Normal  \n",
       "2       -0.3456        0.2685      -0.3587      -0.3587    BLCA  \n",
       "3        0.0015        0.0015       0.0015       0.0015  Normal  \n",
       "4       -0.0024       -0.0024      -0.0024      -0.0024  Normal  \n",
       "\n",
       "[5 rows x 787 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcga['y'] = tcga['y'].replace(['KIRC','KIRP','KICH'],['RC','RC','RC'])\n",
    "tcga.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y  y_encode\n",
       "0    BLCA         0\n",
       "1  Normal        12\n",
       "2    BLCA         0\n",
       "3  Normal        12\n",
       "4  Normal        12"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "tcga[\"y_encode\"] = lb_make.fit_transform(tcga[\"y\"])\n",
    "tcga[[\"y\",\"y_encode\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20715 entries, 0 to 20714\n",
      "Columns: 788 entries, cyto.10p11.1 to y_encode\n",
      "dtypes: float64(786), int64(1), object(1)\n",
      "memory usage: 124.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tcga.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Normal    10170\n",
       "BRCA       1079\n",
       "RC          882\n",
       "OV          582\n",
       "GBM         573\n",
       "UCEC        539\n",
       "HNSC        522\n",
       "LUAD        516\n",
       "LGG         512\n",
       "LUSC        501\n",
       "THCA        499\n",
       "PRAD        492\n",
       "SKCM        469\n",
       "COAD        449\n",
       "STAD        441\n",
       "BLCA        408\n",
       "LIHC        370\n",
       "CESC        295\n",
       "SARC        257\n",
       "LAML        191\n",
       "PAAD        184\n",
       "ESCA        184\n",
       "READ        165\n",
       "PCPG        162\n",
       "TGCT        150\n",
       "THYM        123\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tcga.y.value_counts()))\n",
    "tcga.y.value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tcga.drop(['y','y_encode'], axis=1)\n",
    "y = tcga['y_encode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyto.10p11.1</th>\n",
       "      <th>cyto.10p11.21</th>\n",
       "      <th>cyto.10p11.22</th>\n",
       "      <th>cyto.10p11.23</th>\n",
       "      <th>cyto.10p12.1</th>\n",
       "      <th>cyto.10p12.2</th>\n",
       "      <th>cyto.10p12.31</th>\n",
       "      <th>cyto.10p12.32</th>\n",
       "      <th>cyto.10p12.33</th>\n",
       "      <th>cyto.10p13</th>\n",
       "      <th>...</th>\n",
       "      <th>cyto.9q31.3</th>\n",
       "      <th>cyto.9q32</th>\n",
       "      <th>cyto.9q33.1</th>\n",
       "      <th>cyto.9q33.2</th>\n",
       "      <th>cyto.9q33.3</th>\n",
       "      <th>cyto.9q34.11</th>\n",
       "      <th>cyto.9q34.12</th>\n",
       "      <th>cyto.9q34.13</th>\n",
       "      <th>cyto.9q34.2</th>\n",
       "      <th>cyto.9q34.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.1608</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "      <td>-0.1732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.2733</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.2716</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>-0.3456</td>\n",
       "      <td>0.2685</td>\n",
       "      <td>-0.3587</td>\n",
       "      <td>-0.3587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0057</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>-0.0024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cyto.10p11.1  cyto.10p11.21  cyto.10p11.22  cyto.10p11.23  cyto.10p12.1  \\\n",
       "0       -0.1608         0.2213         0.2213         0.2213        0.2213   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017       -0.0017   \n",
       "2       -0.2733         0.0403         0.0403         0.0403        0.0356   \n",
       "3        0.0013         0.0013         0.0013         0.0013       -0.0057   \n",
       "4       -0.0003        -0.0003        -0.0003        -0.0003       -0.0003   \n",
       "\n",
       "   cyto.10p12.2  cyto.10p12.31  cyto.10p12.32  cyto.10p12.33  cyto.10p13  ...  \\\n",
       "0        0.2213         0.2213         0.2213         0.2213      0.2213  ...   \n",
       "1       -0.0017        -0.0017        -0.0017        -0.0017     -0.0017  ...   \n",
       "2        0.0356         0.0356         0.0356         0.0356      0.0356  ...   \n",
       "3        0.0053         0.0053         0.0053         0.0053      0.0053  ...   \n",
       "4       -0.0002        -0.0002        -0.0002        -0.0002     -0.0002  ...   \n",
       "\n",
       "   cyto.9q31.3  cyto.9q32  cyto.9q33.1  cyto.9q33.2  cyto.9q33.3  \\\n",
       "0      -0.1732    -0.1732      -0.1732      -0.1732      -0.1732   \n",
       "1       0.0009     0.0009       0.0009       0.0009       0.0009   \n",
       "2      -0.2716    -0.2716      -0.2716      -0.2716      -0.2716   \n",
       "3       0.0015     0.0015       0.0015       0.0015       0.0015   \n",
       "4      -0.0024    -0.0024      -0.0024      -0.0024      -0.0024   \n",
       "\n",
       "   cyto.9q34.11  cyto.9q34.12  cyto.9q34.13  cyto.9q34.2  cyto.9q34.3  \n",
       "0       -0.1732       -0.1732       -0.1732      -0.1732      -0.1732  \n",
       "1        0.0009        0.0009        0.0009       0.0009       0.0009  \n",
       "2       -0.3456       -0.3456        0.2685      -0.3587      -0.3587  \n",
       "3        0.0015        0.0015        0.0015       0.0015       0.0015  \n",
       "4       -0.0024       -0.0024       -0.0024      -0.0024      -0.0024  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "standardsc = StandardScaler()\n",
    "mas = MaxAbsScaler()\n",
    "skf = StratifiedKFold(n_splits = 3, random_state=0, shuffle = True)\n",
    "\n",
    "def model_pipeline(model) :\n",
    "    pipeline1 = Pipeline([('StandardScaler', standardsc), ('Logistic', model)])\n",
    "    pipeline3 = Pipeline([('MaxAbsScaler', mas), ('Logistic', model)])\n",
    "\n",
    "    cv_acc = []\n",
    "    pip1_acc = []\n",
    "    pip3_acc = []\n",
    "\n",
    "    for i, (tr_ind, te_ind) in enumerate(skf.split(X,y)) :\n",
    "\n",
    "        X_train, X_test = X.iloc[tr_ind], X.iloc[te_ind]\n",
    "        y_train, y_test = y[tr_ind], y[te_ind]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        pipeline1.fit(X_train, y_train)\n",
    "        pipeline3.fit(X_train, y_train)\n",
    "\n",
    "        cv_acc.append(accuracy_score(y[te_ind], model.predict(X_test)))\n",
    "        pip1_acc.append(accuracy_score(y[te_ind], pipeline1.predict(X_test)))\n",
    "        pip3_acc.append(accuracy_score(y[te_ind], pipeline3.predict(X_test)))\n",
    "\n",
    "        print('{0} 번째 accuracy non_scale : {1:.2f}% StandardScale : {2:.2f}% MaxAbs : {3:.2f}%'.format(i,cv_acc[i]*100,pip1_acc[i]*100,pip3_acc[i]*100))\n",
    "\n",
    "    print('\\n mean accuracy non_scale : {0:.2f}% StandardScale : {1:.2f}% MaxAbs : {2:.2f}%'.format(np.mean(cv_acc)*100,np.mean(pip1_acc)*100,np.mean(pip3_acc)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 80.19% StandardScale : 78.38% MaxAbs : 79.28%\n",
      "1 번째 accuracy non_scale : 79.54% StandardScale : 77.58% MaxAbs : 78.68%\n",
      "2 번째 accuracy non_scale : 80.13% StandardScale : 77.82% MaxAbs : 78.98%\n",
      "\n",
      " mean accuracy non_scale : 79.95% StandardScale : 77.93% MaxAbs : 78.98%\n",
      "sec : 1045.7448925971985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "start_time = time.time()\n",
    "Logis = LogisticRegression(random_state = 0, n_jobs=-1)\n",
    "model_pipeline(Logis)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec :  432.8180446624756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_iter': 10, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Logis = LogisticRegression(random_state = 0, n_jobs=-1)\n",
    "\n",
    "params = { \n",
    "    'penalty':['l1','l2'], \n",
    "    'max_iter' : [10,30,50]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(Logis, param_grid=params, cv= 3, n_jobs=-1)\n",
    "CV_rfc.fit(X,y)\n",
    "print('sec : ',time.time()-start_time)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 79.00% StandardScale : 77.49% MaxAbs : 78.67%\n",
      "1 번째 accuracy non_scale : 78.52% StandardScale : 76.73% MaxAbs : 78.31%\n",
      "2 번째 accuracy non_scale : 79.26% StandardScale : 76.95% MaxAbs : 78.62%\n",
      "\n",
      " mean accuracy non_scale : 78.93% StandardScale : 77.06% MaxAbs : 78.53%\n",
      "sec : 159.39516234397888\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "Logis = LogisticRegression(random_state = 0, n_jobs=-1,max_iter=10, penalty='l1')\n",
    "model_pipeline(Logis)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 65.74% StandardScale : 11.70% MaxAbs : 72.77%\n",
      "1 번째 accuracy non_scale : 65.12% StandardScale : 59.82% MaxAbs : 72.07%\n",
      "2 번째 accuracy non_scale : 66.18% StandardScale : 55.36% MaxAbs : 72.31%\n",
      "3 번째 accuracy non_scale : 64.10% StandardScale : 11.52% MaxAbs : 71.51%\n",
      "4 번째 accuracy non_scale : 65.59% StandardScale : 11.33% MaxAbs : 73.21%\n",
      "\n",
      " mean accuracy non_scale : 65.34% StandardScale : 29.95% MaxAbs : 72.37%\n",
      "sec : 19.700685262680054\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "rf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "model_pipeline(rf)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec :  605.4610633850098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 75, 'n_estimators': 500}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rfc=RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [300,500],\n",
    "    'max_depth' : [75,100]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3, n_jobs=-1)\n",
    "\n",
    "CV_rfc.fit(X,y)\n",
    "print('sec : ',time.time()-start_time)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=-1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 73.99% StandardScale : 18.59% MaxAbs : 79.08%\n",
      "1 번째 accuracy non_scale : 72.81% StandardScale : 17.55% MaxAbs : 77.66%\n",
      "2 번째 accuracy non_scale : 74.22% StandardScale : 18.32% MaxAbs : 78.39%\n",
      "3 번째 accuracy non_scale : 73.33% StandardScale : 16.55% MaxAbs : 77.63%\n",
      "4 번째 accuracy non_scale : 73.26% StandardScale : 45.52% MaxAbs : 78.70%\n",
      "\n",
      " mean accuracy non_scale : 73.52% StandardScale : 23.31% MaxAbs : 78.29%\n",
      "sec : 606.0388605594635\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "rf = RandomForestClassifier(random_state = 0, n_jobs = -1, max_depth=75,n_estimators=500)\n",
    "model_pipeline(rf)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree accuracy : 0.7807\n"
     ]
    }
   ],
   "source": [
    "rf_best = CV_rfc.best_estimator_\n",
    "pred = rf_best.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('decision tree accuracy : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[50]\tvalid_0's multi_logloss: 0.814804\tvalid_0's multi_logloss: 0.814804\n",
      "[100]\tvalid_0's multi_logloss: 0.786545\tvalid_0's multi_logloss: 0.786545\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.779703\tvalid_0's multi_logloss: 0.779703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=200, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=200)\n",
    "\n",
    "evals = [(X_test, Y_test)]\n",
    "lgbm_clf.fit(X_train, Y_train, early_stopping_rounds=30, eval_metric=\"logloss\", eval_set=evals,\n",
    "                verbose=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM accuracy : 0.8018\n"
     ]
    }
   ],
   "source": [
    "pred = lgbm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('LightGBM accuracy : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.295724\tvalid_0's multi_logloss: 0.295724\tvalid_1's multi_logloss: 0.888712\tvalid_1's multi_logloss: 0.888712\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.288231\tvalid_0's multi_logloss: 0.288231\tvalid_1's multi_logloss: 0.876504\tvalid_1's multi_logloss: 0.876504\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.298406\tvalid_0's multi_logloss: 0.298406\tvalid_1's multi_logloss: 0.873047\tvalid_1's multi_logloss: 0.873047\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.295724\tvalid_0's multi_logloss: 0.295724\tvalid_1's multi_logloss: 0.888712\tvalid_1's multi_logloss: 0.888712\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.288231\tvalid_0's multi_logloss: 0.288231\tvalid_1's multi_logloss: 0.876504\tvalid_1's multi_logloss: 0.876504\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.298406\tvalid_0's multi_logloss: 0.298406\tvalid_1's multi_logloss: 0.873047\tvalid_1's multi_logloss: 0.873047\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.303289\tvalid_0's multi_logloss: 0.303289\tvalid_1's multi_logloss: 0.90524\tvalid_1's multi_logloss: 0.90524\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.291899\tvalid_0's multi_logloss: 0.291899\tvalid_1's multi_logloss: 0.890267\tvalid_1's multi_logloss: 0.890267\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 0.293484\tvalid_0's multi_logloss: 0.293484\tvalid_1's multi_logloss: 0.888989\tvalid_1's multi_logloss: 0.888989\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.303289\tvalid_0's multi_logloss: 0.303289\tvalid_1's multi_logloss: 0.90524\tvalid_1's multi_logloss: 0.90524\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.291899\tvalid_0's multi_logloss: 0.291899\tvalid_1's multi_logloss: 0.890267\tvalid_1's multi_logloss: 0.890267\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 0.293484\tvalid_0's multi_logloss: 0.293484\tvalid_1's multi_logloss: 0.888989\tvalid_1's multi_logloss: 0.888989\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.289313\tvalid_0's multi_logloss: 0.289313\tvalid_1's multi_logloss: 0.857148\tvalid_1's multi_logloss: 0.857148\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279812\tvalid_0's multi_logloss: 0.279812\tvalid_1's multi_logloss: 0.842182\tvalid_1's multi_logloss: 0.842182\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.268435\tvalid_0's multi_logloss: 0.268435\tvalid_1's multi_logloss: 0.865949\tvalid_1's multi_logloss: 0.865949\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_logloss: 0.279819\tvalid_0's multi_logloss: 0.279819\tvalid_1's multi_logloss: 0.843664\tvalid_1's multi_logloss: 0.843664\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.289313\tvalid_0's multi_logloss: 0.289313\tvalid_1's multi_logloss: 0.857148\tvalid_1's multi_logloss: 0.857148\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279812\tvalid_0's multi_logloss: 0.279812\tvalid_1's multi_logloss: 0.842182\tvalid_1's multi_logloss: 0.842182\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.268435\tvalid_0's multi_logloss: 0.268435\tvalid_1's multi_logloss: 0.865949\tvalid_1's multi_logloss: 0.865949\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_logloss: 0.279819\tvalid_0's multi_logloss: 0.279819\tvalid_1's multi_logloss: 0.843664\tvalid_1's multi_logloss: 0.843664\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.289843\tvalid_0's multi_logloss: 0.289843\tvalid_1's multi_logloss: 0.864334\tvalid_1's multi_logloss: 0.864334\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.277829\tvalid_0's multi_logloss: 0.277829\tvalid_1's multi_logloss: 0.849381\tvalid_1's multi_logloss: 0.849381\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279485\tvalid_0's multi_logloss: 0.279485\tvalid_1's multi_logloss: 0.845731\tvalid_1's multi_logloss: 0.845731\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.289843\tvalid_0's multi_logloss: 0.289843\tvalid_1's multi_logloss: 0.864334\tvalid_1's multi_logloss: 0.864334\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.277829\tvalid_0's multi_logloss: 0.277829\tvalid_1's multi_logloss: 0.849381\tvalid_1's multi_logloss: 0.849381\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279485\tvalid_0's multi_logloss: 0.279485\tvalid_1's multi_logloss: 0.845731\tvalid_1's multi_logloss: 0.845731\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264187\tvalid_0's multi_logloss: 0.264187\tvalid_1's multi_logloss: 0.831652\tvalid_1's multi_logloss: 0.831652\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.279921\tvalid_0's multi_logloss: 0.279921\tvalid_1's multi_logloss: 0.817174\tvalid_1's multi_logloss: 0.817174\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254273\tvalid_0's multi_logloss: 0.254273\tvalid_1's multi_logloss: 0.817237\tvalid_1's multi_logloss: 0.817237\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.2647\tvalid_0's multi_logloss: 0.2647\tvalid_1's multi_logloss: 0.806519\tvalid_1's multi_logloss: 0.806519\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.261792\tvalid_0's multi_logloss: 0.261792\tvalid_1's multi_logloss: 0.816826\tvalid_1's multi_logloss: 0.816826\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.27632\tvalid_0's multi_logloss: 0.27632\tvalid_1's multi_logloss: 0.805637\tvalid_1's multi_logloss: 0.805637\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264187\tvalid_0's multi_logloss: 0.264187\tvalid_1's multi_logloss: 0.831652\tvalid_1's multi_logloss: 0.831652\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.279921\tvalid_0's multi_logloss: 0.279921\tvalid_1's multi_logloss: 0.817174\tvalid_1's multi_logloss: 0.817174\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254273\tvalid_0's multi_logloss: 0.254273\tvalid_1's multi_logloss: 0.817237\tvalid_1's multi_logloss: 0.817237\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.2647\tvalid_0's multi_logloss: 0.2647\tvalid_1's multi_logloss: 0.806519\tvalid_1's multi_logloss: 0.806519\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.261792\tvalid_0's multi_logloss: 0.261792\tvalid_1's multi_logloss: 0.816826\tvalid_1's multi_logloss: 0.816826\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.27632\tvalid_0's multi_logloss: 0.27632\tvalid_1's multi_logloss: 0.805637\tvalid_1's multi_logloss: 0.805637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264908\tvalid_0's multi_logloss: 0.264908\tvalid_1's multi_logloss: 0.835105\tvalid_1's multi_logloss: 0.835105\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.284859\tvalid_0's multi_logloss: 0.284859\tvalid_1's multi_logloss: 0.819375\tvalid_1's multi_logloss: 0.819375\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254235\tvalid_0's multi_logloss: 0.254235\tvalid_1's multi_logloss: 0.81816\tvalid_1's multi_logloss: 0.81816\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.270898\tvalid_0's multi_logloss: 0.270898\tvalid_1's multi_logloss: 0.805526\tvalid_1's multi_logloss: 0.805526\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.263256\tvalid_0's multi_logloss: 0.263256\tvalid_1's multi_logloss: 0.819938\tvalid_1's multi_logloss: 0.819938\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.279528\tvalid_0's multi_logloss: 0.279528\tvalid_1's multi_logloss: 0.80677\tvalid_1's multi_logloss: 0.80677\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264908\tvalid_0's multi_logloss: 0.264908\tvalid_1's multi_logloss: 0.835105\tvalid_1's multi_logloss: 0.835105\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.284859\tvalid_0's multi_logloss: 0.284859\tvalid_1's multi_logloss: 0.819375\tvalid_1's multi_logloss: 0.819375\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254235\tvalid_0's multi_logloss: 0.254235\tvalid_1's multi_logloss: 0.81816\tvalid_1's multi_logloss: 0.81816\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.270898\tvalid_0's multi_logloss: 0.270898\tvalid_1's multi_logloss: 0.805526\tvalid_1's multi_logloss: 0.805526\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.263256\tvalid_0's multi_logloss: 0.263256\tvalid_1's multi_logloss: 0.819938\tvalid_1's multi_logloss: 0.819938\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.279528\tvalid_0's multi_logloss: 0.279528\tvalid_1's multi_logloss: 0.80677\tvalid_1's multi_logloss: 0.80677\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.295724\tvalid_0's multi_logloss: 0.295724\tvalid_1's multi_logloss: 0.888712\tvalid_1's multi_logloss: 0.888712\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.288231\tvalid_0's multi_logloss: 0.288231\tvalid_1's multi_logloss: 0.876504\tvalid_1's multi_logloss: 0.876504\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.298406\tvalid_0's multi_logloss: 0.298406\tvalid_1's multi_logloss: 0.873047\tvalid_1's multi_logloss: 0.873047\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.295724\tvalid_0's multi_logloss: 0.295724\tvalid_1's multi_logloss: 0.888712\tvalid_1's multi_logloss: 0.888712\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.288231\tvalid_0's multi_logloss: 0.288231\tvalid_1's multi_logloss: 0.876504\tvalid_1's multi_logloss: 0.876504\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.298406\tvalid_0's multi_logloss: 0.298406\tvalid_1's multi_logloss: 0.873047\tvalid_1's multi_logloss: 0.873047\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.303289\tvalid_0's multi_logloss: 0.303289\tvalid_1's multi_logloss: 0.90524\tvalid_1's multi_logloss: 0.90524\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.291899\tvalid_0's multi_logloss: 0.291899\tvalid_1's multi_logloss: 0.890267\tvalid_1's multi_logloss: 0.890267\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 0.293484\tvalid_0's multi_logloss: 0.293484\tvalid_1's multi_logloss: 0.888989\tvalid_1's multi_logloss: 0.888989\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's multi_logloss: 0.303289\tvalid_0's multi_logloss: 0.303289\tvalid_1's multi_logloss: 0.90524\tvalid_1's multi_logloss: 0.90524\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.291899\tvalid_0's multi_logloss: 0.291899\tvalid_1's multi_logloss: 0.890267\tvalid_1's multi_logloss: 0.890267\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's multi_logloss: 0.293484\tvalid_0's multi_logloss: 0.293484\tvalid_1's multi_logloss: 0.888989\tvalid_1's multi_logloss: 0.888989\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.289313\tvalid_0's multi_logloss: 0.289313\tvalid_1's multi_logloss: 0.857148\tvalid_1's multi_logloss: 0.857148\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279812\tvalid_0's multi_logloss: 0.279812\tvalid_1's multi_logloss: 0.842182\tvalid_1's multi_logloss: 0.842182\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.268435\tvalid_0's multi_logloss: 0.268435\tvalid_1's multi_logloss: 0.865949\tvalid_1's multi_logloss: 0.865949\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_logloss: 0.279819\tvalid_0's multi_logloss: 0.279819\tvalid_1's multi_logloss: 0.843664\tvalid_1's multi_logloss: 0.843664\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.289313\tvalid_0's multi_logloss: 0.289313\tvalid_1's multi_logloss: 0.857148\tvalid_1's multi_logloss: 0.857148\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279812\tvalid_0's multi_logloss: 0.279812\tvalid_1's multi_logloss: 0.842182\tvalid_1's multi_logloss: 0.842182\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.268435\tvalid_0's multi_logloss: 0.268435\tvalid_1's multi_logloss: 0.865949\tvalid_1's multi_logloss: 0.865949\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's multi_logloss: 0.279819\tvalid_0's multi_logloss: 0.279819\tvalid_1's multi_logloss: 0.843664\tvalid_1's multi_logloss: 0.843664\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.289843\tvalid_0's multi_logloss: 0.289843\tvalid_1's multi_logloss: 0.864334\tvalid_1's multi_logloss: 0.864334\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.277829\tvalid_0's multi_logloss: 0.277829\tvalid_1's multi_logloss: 0.849381\tvalid_1's multi_logloss: 0.849381\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279485\tvalid_0's multi_logloss: 0.279485\tvalid_1's multi_logloss: 0.845731\tvalid_1's multi_logloss: 0.845731\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.289843\tvalid_0's multi_logloss: 0.289843\tvalid_1's multi_logloss: 0.864334\tvalid_1's multi_logloss: 0.864334\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.277829\tvalid_0's multi_logloss: 0.277829\tvalid_1's multi_logloss: 0.849381\tvalid_1's multi_logloss: 0.849381\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.279485\tvalid_0's multi_logloss: 0.279485\tvalid_1's multi_logloss: 0.845731\tvalid_1's multi_logloss: 0.845731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264187\tvalid_0's multi_logloss: 0.264187\tvalid_1's multi_logloss: 0.831652\tvalid_1's multi_logloss: 0.831652\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.279921\tvalid_0's multi_logloss: 0.279921\tvalid_1's multi_logloss: 0.817174\tvalid_1's multi_logloss: 0.817174\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254273\tvalid_0's multi_logloss: 0.254273\tvalid_1's multi_logloss: 0.817237\tvalid_1's multi_logloss: 0.817237\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.2647\tvalid_0's multi_logloss: 0.2647\tvalid_1's multi_logloss: 0.806519\tvalid_1's multi_logloss: 0.806519\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.261792\tvalid_0's multi_logloss: 0.261792\tvalid_1's multi_logloss: 0.816826\tvalid_1's multi_logloss: 0.816826\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.27632\tvalid_0's multi_logloss: 0.27632\tvalid_1's multi_logloss: 0.805637\tvalid_1's multi_logloss: 0.805637\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264187\tvalid_0's multi_logloss: 0.264187\tvalid_1's multi_logloss: 0.831652\tvalid_1's multi_logloss: 0.831652\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.279921\tvalid_0's multi_logloss: 0.279921\tvalid_1's multi_logloss: 0.817174\tvalid_1's multi_logloss: 0.817174\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254273\tvalid_0's multi_logloss: 0.254273\tvalid_1's multi_logloss: 0.817237\tvalid_1's multi_logloss: 0.817237\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.2647\tvalid_0's multi_logloss: 0.2647\tvalid_1's multi_logloss: 0.806519\tvalid_1's multi_logloss: 0.806519\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.261792\tvalid_0's multi_logloss: 0.261792\tvalid_1's multi_logloss: 0.816826\tvalid_1's multi_logloss: 0.816826\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's multi_logloss: 0.27632\tvalid_0's multi_logloss: 0.27632\tvalid_1's multi_logloss: 0.805637\tvalid_1's multi_logloss: 0.805637\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264908\tvalid_0's multi_logloss: 0.264908\tvalid_1's multi_logloss: 0.835105\tvalid_1's multi_logloss: 0.835105\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.284859\tvalid_0's multi_logloss: 0.284859\tvalid_1's multi_logloss: 0.819375\tvalid_1's multi_logloss: 0.819375\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254235\tvalid_0's multi_logloss: 0.254235\tvalid_1's multi_logloss: 0.81816\tvalid_1's multi_logloss: 0.81816\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.270898\tvalid_0's multi_logloss: 0.270898\tvalid_1's multi_logloss: 0.805526\tvalid_1's multi_logloss: 0.805526\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.263256\tvalid_0's multi_logloss: 0.263256\tvalid_1's multi_logloss: 0.819938\tvalid_1's multi_logloss: 0.819938\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.279528\tvalid_0's multi_logloss: 0.279528\tvalid_1's multi_logloss: 0.80677\tvalid_1's multi_logloss: 0.80677\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.264908\tvalid_0's multi_logloss: 0.264908\tvalid_1's multi_logloss: 0.835105\tvalid_1's multi_logloss: 0.835105\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.284859\tvalid_0's multi_logloss: 0.284859\tvalid_1's multi_logloss: 0.819375\tvalid_1's multi_logloss: 0.819375\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.254235\tvalid_0's multi_logloss: 0.254235\tvalid_1's multi_logloss: 0.81816\tvalid_1's multi_logloss: 0.81816\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.270898\tvalid_0's multi_logloss: 0.270898\tvalid_1's multi_logloss: 0.805526\tvalid_1's multi_logloss: 0.805526\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.263256\tvalid_0's multi_logloss: 0.263256\tvalid_1's multi_logloss: 0.819938\tvalid_1's multi_logloss: 0.819938\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.279528\tvalid_0's multi_logloss: 0.279528\tvalid_1's multi_logloss: 0.80677\tvalid_1's multi_logloss: 0.80677\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 0.0221061\tvalid_0's multi_logloss: 0.0221061\tvalid_1's multi_logloss: 0.767804\tvalid_1's multi_logloss: 0.767804\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 0.0445088\tvalid_0's multi_logloss: 0.0445088\tvalid_1's multi_logloss: 0.759235\tvalid_1's multi_logloss: 0.759235\n",
      "GridSearchCV 최적 파라미터: {'subsample': 0.8, 'num_leaves': 32, 'min_child_samples': 100, 'max_depth': 128}\n",
      "LightGBM accuracy : 0.8010\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "LGBM_clf = LGBMClassifier(n_estimators=200)\n",
    "evals = [(X_train,Y_train),(X_test, Y_test)]\n",
    "params = {'num_leaves': [32, 64 ],\n",
    "          'max_depth':[128, 160],\n",
    "          'min_child_samples':[40, 60, 100],\n",
    "          'subsample':[0.8, 1]}\n",
    "\n",
    "# 하이퍼 파라미터 테스트의 수행속도를 향상 시키기 위해 cv 를 지정하지 않습니다. \n",
    "gridcv = GridSearchCV(LGBM_clf, param_grid=params)\n",
    "gridcv.fit(X_train, Y_train, early_stopping_rounds=30, eval_metric=\"logloss\", eval_set=evals,verbose=100)\n",
    "\n",
    "print('GridSearchCV 최적 파라미터:', gridcv.best_params_)\n",
    "pred = gridcv.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, pred)\n",
    "print('LightGBM accuracy : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 71.76% StandardScale : 59.04% MaxAbs : 66.48%\n",
      "1 번째 accuracy non_scale : 69.97% StandardScale : 59.03% MaxAbs : 66.16%\n",
      "2 번째 accuracy non_scale : 70.55% StandardScale : 59.58% MaxAbs : 66.08%\n",
      "3 번째 accuracy non_scale : 70.36% StandardScale : 59.70% MaxAbs : 65.98%\n",
      "4 번째 accuracy non_scale : 70.14% StandardScale : 59.34% MaxAbs : 66.41%\n",
      "\n",
      " mean accuracy non_scale : 70.55% StandardScale : 59.34% MaxAbs : 66.22%\n",
      "sec : 2633.9970395565033\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "start_time = time.time()\n",
    "svm = SVC(random_state = 0)\n",
    "model_pipeline(svm)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001, 0.00001, 10]}\n",
    " \n",
    "# Make grid search classifier\n",
    "clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)\n",
    " \n",
    "# Train the classifier\n",
    "clf_grid.fit(X_train, Y_train)\n",
    " \n",
    "# clf = grid.best_estimator_()\n",
    "print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
    "print(\"Best Estimators:\\n\", clf_grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 46.67% StandardScale : 2.22% MaxAbs : 57.14%\n",
      "1 번째 accuracy non_scale : 45.79% StandardScale : 3.33% MaxAbs : 58.09%\n",
      "2 번째 accuracy non_scale : 51.40% StandardScale : 4.93% MaxAbs : 60.16%\n",
      "3 번째 accuracy non_scale : 48.10% StandardScale : 2.68% MaxAbs : 55.86%\n",
      "4 번째 accuracy non_scale : 50.10% StandardScale : 3.65% MaxAbs : 62.08%\n",
      "\n",
      " mean accuracy non_scale : 48.41% StandardScale : 3.36% MaxAbs : 58.67%\n",
      "sec : 576.410329580307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "start_time = time.time()\n",
    "ada = AdaBoostClassifier(random_state = 0)\n",
    "model_pipeline(ada)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 accuracy non_scale : 66.66% StandardScale : 2.34% MaxAbs : 79.25%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ac2426584eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sec :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7bc6da49b643>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpipeline1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpipeline3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcv_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "start_time = time.time()\n",
    "gbm = GradientBoostingClassifier(random_state = 0)\n",
    "model_pipeline(gbm)\n",
    "print('sec :',time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
